{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 sensory-visual neuron IDs\n",
      "Epoch 1/10:\n",
      "  Train Loss: 1.3183 | Acc: 46.00%\n",
      "  Test  Acc: 82.95%\n",
      "--------------------------------------------------\n",
      "Epoch 2/10:\n",
      "  Train Loss: 0.3221 | Acc: 90.99%\n",
      "  Test  Acc: 92.73%\n",
      "--------------------------------------------------\n",
      "Epoch 3/10:\n",
      "  Train Loss: 0.2280 | Acc: 93.60%\n",
      "  Test  Acc: 94.95%\n",
      "--------------------------------------------------\n",
      "Epoch 4/10:\n",
      "  Train Loss: 0.1867 | Acc: 94.77%\n",
      "  Test  Acc: 94.44%\n",
      "--------------------------------------------------\n",
      "Epoch 5/10:\n",
      "  Train Loss: 0.1679 | Acc: 95.26%\n",
      "  Test  Acc: 95.40%\n",
      "--------------------------------------------------\n",
      "Epoch 6/10:\n",
      "  Train Loss: 0.1497 | Acc: 95.74%\n",
      "  Test  Acc: 94.06%\n",
      "--------------------------------------------------\n",
      "Epoch 7/10:\n",
      "  Train Loss: 0.1359 | Acc: 96.10%\n",
      "  Test  Acc: 95.81%\n",
      "--------------------------------------------------\n",
      "Epoch 8/10:\n",
      "  Train Loss: 0.1253 | Acc: 96.35%\n",
      "  Test  Acc: 95.83%\n",
      "--------------------------------------------------\n",
      "Epoch 9/10:\n",
      "  Train Loss: 0.1117 | Acc: 96.67%\n",
      "  Test  Acc: 96.24%\n",
      "--------------------------------------------------\n",
      "Epoch 10/10:\n",
      "  Train Loss: 0.1015 | Acc: 96.98%\n",
      "  Test  Acc: 96.05%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# --------------------- 数据预处理部分 ---------------------\n",
    "def load_connectivity_data(connectivity_path, annotation_path):\n",
    "    \"\"\"加载并预处理连接矩阵和注释数据\"\"\"\n",
    "    # 加载注释文件\n",
    "    df_annot = pd.read_csv(annotation_path)\n",
    "  \n",
    "    # 提取视觉感觉神经元ID\n",
    "    mask = (df_annot['celltype'] == 'sensory') & (df_annot['additional_annotations'] == 'visual')\n",
    "    sensory_visual_ids = []\n",
    "    for _, row in df_annot[mask].iterrows():\n",
    "        for col in ['left_id', 'right_id']:\n",
    "            if (id_str := str(row[col]).lower()) != \"no pair\":\n",
    "                sensory_visual_ids.append(int(id_str))\n",
    "  \n",
    "    # 去重排序\n",
    "    sensory_visual_ids = sorted(list(set(sensory_visual_ids)))\n",
    "    print(f\"Found {len(sensory_visual_ids)} sensory-visual neuron IDs\")\n",
    "  \n",
    "    # 加载连接矩阵\n",
    "    df_conn = pd.read_csv(connectivity_path, index_col=0)\n",
    "    df_conn.index = df_conn.index.astype(int)\n",
    "    df_conn.columns = df_conn.columns.astype(int)\n",
    "  \n",
    "    # 筛选有效ID\n",
    "    valid_sensory_ids = [nid for nid in sensory_visual_ids if nid in df_conn.index]\n",
    "    other_ids = [nid for nid in df_conn.index if nid not in valid_sensory_ids]\n",
    "  \n",
    "    # 重新排序矩阵\n",
    "    df_reindexed = df_conn.loc[valid_sensory_ids + other_ids, valid_sensory_ids + other_ids]\n",
    "  \n",
    "    # 标准化并拆分矩阵\n",
    "    adj_matrix = df_reindexed.values * 1e-3  # 统一标准化\n",
    "  \n",
    "    num_S = len(valid_sensory_ids)\n",
    "    return {\n",
    "        'W_ss': adj_matrix[:num_S, :num_S],\n",
    "        'W_sr': adj_matrix[:num_S, num_S:],\n",
    "        'W_rs': adj_matrix[num_S:, :num_S],\n",
    "        'W_rr': adj_matrix[num_S:, num_S:],\n",
    "        'sensory_ids': valid_sensory_ids\n",
    "    }\n",
    "\n",
    "# --------------------- 模型定义部分 ---------------------\n",
    "class DrosophilaRNN(nn.Module):\n",
    "    def __init__(self, input_dim, sensory_dim, residual_dim, num_classes, conn_weights):\n",
    "        super().__init__()\n",
    "        # 初始化连接权重\n",
    "        self.W_ss = nn.Parameter(torch.tensor(conn_weights['W_ss'], dtype=torch.float32), requires_grad=True)\n",
    "        self.W_sr = nn.Parameter(torch.tensor(conn_weights['W_sr'], dtype=torch.float32), requires_grad=True)\n",
    "        self.W_rs = nn.Parameter(torch.tensor(conn_weights['W_rs'], dtype=torch.float32), requires_grad=True)\n",
    "        self.W_rr = nn.Parameter(torch.tensor(conn_weights['W_rr'], dtype=torch.float32), requires_grad=True)\n",
    "      \n",
    "        # 定义网络层\n",
    "        self.input_proj = nn.Linear(input_dim, sensory_dim)\n",
    "        self.output_layer = nn.Linear(residual_dim, num_classes)\n",
    "        self.activation = nn.ReLU()\n",
    "      \n",
    "        # 维度验证\n",
    "        assert self.W_ss.shape == (sensory_dim, sensory_dim)\n",
    "        assert self.W_sr.shape == (sensory_dim, residual_dim)\n",
    "        assert self.W_rs.shape == (residual_dim, sensory_dim)\n",
    "        assert self.W_rr.shape == (residual_dim, residual_dim)\n",
    "\n",
    "    def forward(self, x, time_steps=10):\n",
    "        batch_size = x.shape[0]\n",
    "        device = x.device\n",
    "      \n",
    "        # 初始化状态\n",
    "        S = torch.zeros(batch_size, self.W_ss.shape[0], device=device)\n",
    "        R = torch.zeros(batch_size, self.W_rr.shape[0], device=device)\n",
    "      \n",
    "        # 输入投影\n",
    "        E = self.input_proj(x)  # [batch_size, sensory_dim]\n",
    "      \n",
    "        # 时间步模拟\n",
    "        for t in range(time_steps):\n",
    "            # 每10步注入输入\n",
    "            E_t = E if t % 5 == 0 else torch.zeros_like(E)\n",
    "          \n",
    "            # 感觉神经元更新\n",
    "            S_next = self.activation(\n",
    "                S @ self.W_ss +    # S->S连接\n",
    "                E_t +             # 外部输入\n",
    "                R @ self.W_rs     # R->S连接\n",
    "            )\n",
    "          \n",
    "            # 残留神经元更新\n",
    "            R_next = self.activation(\n",
    "                R @ self.W_rr +    # R->R连接\n",
    "                S @ self.W_sr      # S->R连接\n",
    "            )\n",
    "          \n",
    "            S, R = S_next, R_next\n",
    "      \n",
    "        return self.output_layer(R)\n",
    "\n",
    "# --------------------- 训练流程部分 ---------------------\n",
    "def main():\n",
    "    # 加载连接数据\n",
    "    conn_data = load_connectivity_data(\n",
    "        # connectivity_path=\"./data/ad_connectivity_matrix.csv\",\n",
    "        connectivity_path=\"./data/signed_connectivity_matrix.csv\",\n",
    "        annotation_path=\"./data/science.add9330_data_s2.csv\"\n",
    "    )\n",
    "  \n",
    "    # 初始化模型\n",
    "    model = DrosophilaRNN(\n",
    "        input_dim=784,\n",
    "        sensory_dim=len(conn_data['sensory_ids']),\n",
    "        residual_dim=conn_data['W_rr'].shape[0],\n",
    "        num_classes=10,\n",
    "        conn_weights=conn_data\n",
    "    )\n",
    "    results = {\n",
    "        \"epoch_train_loss\": [],\n",
    "        \"epoch_train_acc\": [],\n",
    "        \"epoch_test_acc\": [],\n",
    "        \"flops_acc\": [],       # 保持结构一致（暂未实现FLOPs计算）\n",
    "        \"total_flops\": 0,      # 保持结构一致\n",
    "        \"activations\": None    # 保持结构一致\n",
    "    }\n",
    "\n",
    "    # 数据加载\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "  \n",
    "    train_loader = DataLoader(\n",
    "        datasets.MNIST('./data', train=True, download=True, transform=transform),\n",
    "        batch_size=64, shuffle=True\n",
    "    )\n",
    "  \n",
    "    test_loader = DataLoader(\n",
    "        datasets.MNIST('./data', train=False, transform=transform),\n",
    "        batch_size=64, shuffle=False\n",
    "    )\n",
    "  \n",
    "    # 训练配置\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "  \n",
    "    # 训练循环\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        total_loss, correct = 0.0, 0\n",
    "      \n",
    "        # 训练阶段\n",
    "        for images, labels in train_loader:\n",
    "            images = images.view(-1, 784).to(device)\n",
    "            labels = labels.to(device)\n",
    "          \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "          \n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += (pred == labels).sum().item()\n",
    "      \n",
    "        # 记录训练指标\n",
    "        train_loss = total_loss / len(train_loader.dataset)\n",
    "        train_acc = 100. * correct / len(train_loader.dataset)\n",
    "        results[\"epoch_train_loss\"].append(train_loss)\n",
    "        results[\"epoch_train_acc\"].append(train_acc/100)  # 转换为0-1范围\n",
    "      \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images = images.view(-1, 784).to(device)\n",
    "                labels = labels.to(device)\n",
    "              \n",
    "                outputs = model(images)\n",
    "                test_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "      \n",
    "        # 记录测试指标\n",
    "        test_acc = 100. * test_correct / len(test_loader.dataset)\n",
    "        results[\"epoch_test_acc\"].append(test_acc/100)  # 转换为0-1范围\n",
    "      \n",
    "        # 打印统计信息\n",
    "        print(f\"Epoch {epoch+1}/10:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Test  Acc: {test_acc:.2f}%\")\n",
    "        print(\"-\" * 50)\n",
    "  \n",
    "    # 保存结果\n",
    "    with open(\"Drosophila_Metrics.signed.pkl\", \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
