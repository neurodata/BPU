{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Learnable_DPU_fewshot_120 Trial 1 ===\n",
      "========================================\n",
      "Starting Experiment: Learnable_DPU_fewshot_120 Trial 1\n",
      "Experiment configuration:\n",
      "  type: drosophilarnn\n",
      "  trainable: True\n",
      "  pruning: {'enable': True, 'constraint': 'structure', 'lambda_reg': 0.0002, 'max_iter': 200, 'fista_threshold': 0.01, 'fista_gamma': 0.7}\n",
      "  init: droso\n",
      "  ref: droso\n",
      "  fewshot: 120\n",
      "  fewshot_batch_size: 17\n",
      "========================================\n",
      "\n",
      "Found 29 sensory-visual neuron IDs\n",
      "Found 29 sensory-visual neuron IDs\n",
      "Trial 1 | Epoch 0 | Test Acc: 9.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 71/71 [00:05<00:00, 12.24batch/s, loss=1.8566, train_acc=13.17%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Similarity Metrics: Overlap ratio: 0.9997, Non-zero count of X: 63525, Non-zero count of W_ref: 63545, Overlap of non-zero positions: 63525, L1 error: 266.1201, L2 error: 1.6461\n",
      "submodule nonzero values: {'input_proj': 22765, 'output_layer': 29240, 'activation': 0, 'total': 115530}\n",
      "Trial 1 | Epoch 1 | Test Acc: 10.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 71/71 [00:05<00:00, 12.51batch/s, loss=2.1251, train_acc=15.33%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Similarity Metrics: Overlap ratio: 0.9753, Non-zero count of X: 61977, Non-zero count of W_ref: 63545, Overlap of non-zero positions: 61977, L1 error: 362.9801, L2 error: 2.2061\n",
      "submodule nonzero values: {'input_proj': 22765, 'output_layer': 29240, 'activation': 0, 'total': 113982}\n",
      "Trial 1 | Epoch 2 | Test Acc: 9.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 71/71 [00:05<00:00, 12.19batch/s, loss=2.0330, train_acc=19.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Similarity Metrics: Overlap ratio: 0.9682, Non-zero count of X: 61527, Non-zero count of W_ref: 63545, Overlap of non-zero positions: 61527, L1 error: 431.2100, L2 error: 2.6094\n",
      "submodule nonzero values: {'input_proj': 22765, 'output_layer': 29240, 'activation': 0, 'total': 113532}\n",
      "Trial 1 | Epoch 3 | Test Acc: 9.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 71/71 [00:05<00:00, 12.17batch/s, loss=2.0923, train_acc=19.25%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Similarity Metrics: Overlap ratio: 0.9655, Non-zero count of X: 61353, Non-zero count of W_ref: 63545, Overlap of non-zero positions: 61353, L1 error: 483.3000, L2 error: 2.9465\n",
      "submodule nonzero values: {'input_proj': 22765, 'output_layer': 29240, 'activation': 0, 'total': 113358}\n",
      "Trial 1 | Epoch 4 | Test Acc: 9.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 71/71 [00:05<00:00, 12.07batch/s, loss=1.9695, train_acc=19.67%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Similarity Metrics: Overlap ratio: 0.9649, Non-zero count of X: 61317, Non-zero count of W_ref: 63545, Overlap of non-zero positions: 61317, L1 error: 523.6900, L2 error: 3.2529\n",
      "submodule nonzero values: {'input_proj': 22765, 'output_layer': 29240, 'activation': 0, 'total': 113322}\n",
      "Trial 1 | Epoch 5 | Test Acc: 9.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 71/71 [00:06<00:00, 11.64batch/s, loss=1.8460, train_acc=21.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Similarity Metrics: Overlap ratio: 0.9647, Non-zero count of X: 61300, Non-zero count of W_ref: 63545, Overlap of non-zero positions: 61300, L1 error: 572.0800, L2 error: 3.6243\n",
      "submodule nonzero values: {'input_proj': 22765, 'output_layer': 29240, 'activation': 0, 'total': 113305}\n",
      "Trial 1 | Epoch 6 | Test Acc: 9.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 71/71 [00:05<00:00, 12.18batch/s, loss=1.9672, train_acc=21.17%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Similarity Metrics: Overlap ratio: 0.9651, Non-zero count of X: 61325, Non-zero count of W_ref: 63545, Overlap of non-zero positions: 61325, L1 error: 605.8600, L2 error: 3.9145\n",
      "submodule nonzero values: {'input_proj': 22765, 'output_layer': 29240, 'activation': 0, 'total': 113330}\n",
      "Trial 1 | Epoch 7 | Test Acc: 9.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 71/71 [00:05<00:00, 12.40batch/s, loss=2.4278, train_acc=21.33%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Similarity Metrics: Overlap ratio: 0.9650, Non-zero count of X: 61321, Non-zero count of W_ref: 63545, Overlap of non-zero positions: 61321, L1 error: 659.2700, L2 error: 4.3216\n",
      "submodule nonzero values: {'input_proj': 22765, 'output_layer': 29240, 'activation': 0, 'total': 113326}\n",
      "Trial 1 | Epoch 8 | Test Acc: 9.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 71/71 [00:05<00:00, 11.92batch/s, loss=2.0277, train_acc=19.83%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Similarity Metrics: Overlap ratio: 0.9635, Non-zero count of X: 61226, Non-zero count of W_ref: 63545, Overlap of non-zero positions: 61226, L1 error: 746.4200, L2 error: 4.8701\n",
      "submodule nonzero values: {'input_proj': 22765, 'output_layer': 29240, 'activation': 0, 'total': 113231}\n",
      "Trial 1 | Epoch 9 | Test Acc: 9.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 71/71 [00:05<00:00, 12.26batch/s, loss=1.8840, train_acc=23.75%]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from net import *\n",
    "from connectome_utils import *\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Load config\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config_data = yaml.safe_load(f)\n",
    "\n",
    "# Global parameters\n",
    "signed = config_data.get(\"signed\", True)\n",
    "num_trials = config_data.get(\"num_trials\", 10)\n",
    "num_epochs = config_data.get(\"num_epochs\", 10)\n",
    "batch_size = config_data.get(\"batch_size\", 64)\n",
    "learning_rate = config_data.get(\"learning_rate\", 0.001)\n",
    "experiments = config_data.get(\"experiments\", {})\n",
    "\n",
    "# Few-shot settings\n",
    "fewshot_config = config_data.get(\"fewshot\", {})\n",
    "fewshot_enabled = fewshot_config.get(\"enabled\", False)\n",
    "fewshot_samples = fewshot_config.get(\"samples\", 60)\n",
    "fewshot_batch_size = fewshot_config.get(\"batch_size\", 10)\n",
    "if fewshot_enabled:\n",
    "    fewshot_experiments = {}\n",
    "    for exp_id, exp_config in experiments.items():\n",
    "        cfg = exp_config.copy()\n",
    "        cfg[\"fewshot\"] = fewshot_samples\n",
    "        cfg[\"fewshot_batch_size\"] = fewshot_batch_size\n",
    "        fewshot_experiments[f\"{exp_id}_fewshot_{fewshot_samples}\"] = cfg\n",
    "    experiments = fewshot_experiments\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create stratified few-shot subset\n",
    "def create_fewshot_subset(dataset, seed, samples_per_class=60):\n",
    "    targets = np.array(dataset.targets)\n",
    "    train_size = (samples_per_class * 10) / len(targets)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, train_size=train_size, random_state=seed)\n",
    "    indices, _ = next(sss.split(np.zeros_like(targets), targets))\n",
    "    return torch.utils.data.Subset(dataset, indices)\n",
    "\n",
    "def prepare_input(data, model):\n",
    "    return data if isinstance(model, CNNRNN) else data.squeeze(1)\n",
    "\n",
    "def get_weight_matrix(base, mode, trainable=True):\n",
    "    if mode == 'random':\n",
    "        arr_np = np.random.randn(*base.shape).astype(np.float32)\n",
    "        return arr_np\n",
    "    \n",
    "    elif mode == 'droso':\n",
    "        return base\n",
    "    \n",
    "    elif mode == 'randsparse':\n",
    "        non_zero = np.count_nonzero(base)\n",
    "        mask = np.zeros(base.shape, dtype=np.float32)\n",
    "        idx = np.random.permutation(mask.size)[:non_zero]\n",
    "        mask.flat[idx] = 1\n",
    "        arr_np = np.random.randn(*base.shape).astype(np.float32) * mask\n",
    "        return arr_np\n",
    "    \n",
    "    elif mode == 'randstructure':\n",
    "        mask = (base != 0).astype(np.float32)\n",
    "        arr_np = np.abs(np.random.randn(*base.shape).astype(np.float32)) * mask\n",
    "        return arr_np\n",
    "    \n",
    "    else:\n",
    "        return base if not trainable else None\n",
    "\n",
    "\n",
    "def load_base_matrix(cfg_data, signed, config):\n",
    "    path = cfg_data[\"csv_paths\"][\"signed\"] if signed else cfg_data[\"csv_paths\"][\"unsigned\"]\n",
    "    if config.get('pruning') == 'drosophila':\n",
    "        W, _ = load_drosophila_matrix(path, apply_pruning=True, signed=signed)\n",
    "    else:\n",
    "        W = load_drosophila_matrix(path, apply_pruning=False, signed=signed)\n",
    "    return W\n",
    "\n",
    "def load_connectivity_info(mode, W_matrix, SIO, cfg_data):\n",
    "    if mode == 'droso':\n",
    "        if SIO:\n",
    "            return load_sio_connectivity_data(\n",
    "                connectivity_path=cfg_data[\"csv_paths\"][\"signed\"],\n",
    "                annotation_path=cfg_data[\"annotation_path\"]\n",
    "            )\n",
    "        else:\n",
    "            return load_connectivity_data(\n",
    "                connectivity_path=cfg_data[\"csv_paths\"][\"signed\"],\n",
    "                annotation_path=cfg_data[\"annotation_path\"]\n",
    "            )\n",
    "    else:\n",
    "        return load_random_matrix(W_matrix, 29)\n",
    "\n",
    "def load_datasets(transform):\n",
    "    train_set = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "    test_set = datasets.MNIST('./data', train=False, transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False)\n",
    "    return train_set, test_loader\n",
    "\n",
    "def initialize_model(config, W_droso):\n",
    "    if config['type'] == 'drosophilarnn':\n",
    "        W_init = get_weight_matrix(W_droso, config.get('init'), config.get('trainable', True))\n",
    "        conn = load_connectivity_info(config.get('init'), W_init, config.get('SIO', False), config_data)\n",
    "        W_ref, ref = None, None\n",
    "        pruning_cfg = config.get('pruning', {})\n",
    "        pruning_enabled = pruning_cfg.get(\"enable\", False)\n",
    "        if pruning_enabled:\n",
    "            W_ref = get_weight_matrix(W_droso, config.get('ref'))\n",
    "            ref = load_connectivity_info(config.get('ref'), W_ref, config.get('SIO', False), config_data)\n",
    "        return DrosophilaRNN(\n",
    "            input_dim=784,\n",
    "            num_classes=10,\n",
    "            conn_weights=conn,\n",
    "            ref_weights=ref,\n",
    "            trainable=config.get('trainable'),\n",
    "            pruning=pruning_enabled,\n",
    "            SIO=config.get('SIO'),\n",
    "            pruning_cfg=pruning_cfg\n",
    "        )\n",
    "    elif config['type'] == 'singlemlp':\n",
    "        return SingleMLP(784, W_droso.shape[0], 10)\n",
    "    elif config['type'] == 'twohiddenmlp':\n",
    "        return TwohiddenMLP(784, 300, 10)\n",
    "    elif config['type'] == 'staticmlp':\n",
    "        return StaticMLP(784, 300, 10)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {config['type']}\")\n",
    "\n",
    "# Train one epoch\n",
    "def train_epoch(model, optimizer, criterion, train_loader):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    pbar = tqdm(train_loader, unit=\"batch\", desc=\"Training\")\n",
    "    for data, target in pbar:\n",
    "        data = prepare_input(data.to(device), model)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # If RNN specifically requires flattening:\n",
    "        data = data.view(data.size(0), -1)\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.size(0)\n",
    "        correct += output.argmax(dim=1).eq(target).sum().item()\n",
    "        total += data.size(0)\n",
    "        train_acc = correct / total if total else 0\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\", train_acc=f\"{train_acc:.2%}\")\n",
    "    \n",
    "    similarity_dict = {}\n",
    "    if hasattr(model, \"apply_structure_constraint_pruning\") and model.pruning and model.pruning_constraint=='structure':\n",
    "        similarity_dict = model.apply_structure_constraint_pruning()\n",
    "    elif hasattr(model, \"apply_sparsity_constraint_pruning\") and model.pruning and model.pruning_constraint=='sparsity':\n",
    "        similarity_dict = model.apply_sparsity_constraint_pruning()\n",
    "\n",
    "    print(similarity_dict)\n",
    "    return total_loss / total, correct / total, similarity_dict\n",
    "\n",
    "# Evaluate model and compute inference FLOPs\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = prepare_input(data.to(device), model)\n",
    "            target = target.to(device)\n",
    "            if isinstance(model, DrosophilaRNN):\n",
    "                data = data.view(data.size(0), -1)\n",
    "            output = model(data)\n",
    "            correct += output.argmax(dim=1).eq(target).sum().item()\n",
    "            total += target.size(0)\n",
    "    acc = correct / total if total > 0 else 0\n",
    "    return acc\n",
    "\n",
    "# Run training loop and record results\n",
    "def run_training_loop(model, config, full_train_set, test_loader, trial_num, num_epochs, batch_size, fewshot_batch_size):\n",
    "    results = {\"epoch_train_loss\": [],\n",
    "               \"epoch_train_acc\": [],\n",
    "               \"epoch_test_acc\": [],\n",
    "               'submodules_nonzero': [],\n",
    "               'similarity_dict': []}\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # initial evaluation for epoch 0\n",
    "    init_acc = evaluate(model, test_loader)\n",
    "    results[\"epoch_test_acc\"].append(init_acc)\n",
    "\n",
    "    print(f\"Trial {trial_num} | Epoch 0 | Test Acc: {init_acc:.2%}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        if \"fewshot\" in config:\n",
    "            subset = create_fewshot_subset(full_train_set, epoch, config[\"fewshot\"])\n",
    "            train_loader = torch.utils.data.DataLoader(subset, batch_size=config.get(\"fewshot_batch_size\", fewshot_batch_size), shuffle=True)\n",
    "        else:\n",
    "            train_loader = torch.utils.data.DataLoader(full_train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        epoch_loss, epoch_acc, similarity_dict = train_epoch(model, optimizer, criterion, train_loader)\n",
    "\n",
    "        results[\"epoch_train_loss\"].append(epoch_loss)\n",
    "        results[\"epoch_train_acc\"].append(epoch_acc)\n",
    "        results[\"similarity_dict\"].append(similarity_dict)\n",
    "\n",
    "        test_acc = evaluate(model, test_loader)\n",
    "\n",
    "        # save for futher flops calculation\n",
    "        submodule_nonzero_dict = {}\n",
    "        for name, submodule in model.named_children():\n",
    "            sub_nonzero = 0\n",
    "            # If you want deeper submodules, consider submodule.named_modules()\n",
    "            for param in submodule.parameters(recurse=False):\n",
    "                sub_nonzero += torch.count_nonzero(param).item()\n",
    "            submodule_nonzero_dict[name] = sub_nonzero\n",
    "        submodule_nonzero_dict['total'] = sum(torch.count_nonzero(p).item() for p in model.parameters())\n",
    "        results['submodules_nonzero'].append(submodule_nonzero_dict)\n",
    "        results[\"epoch_test_acc\"].append(test_acc)\n",
    "\n",
    "        print(f\"submodule nonzero values: {submodule_nonzero_dict}\")\n",
    "        print(f\"Trial {trial_num} | Epoch {epoch+1} | Test Acc: {test_acc:.2%}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def save_results(exp_id, config, trial_num, results, signed):\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    filename = f\"{exp_id}_trial{trial_num}\"\n",
    "    if \"fewshot\" in config:\n",
    "        filename = f\"{exp_id}_trial{trial_num}\"\n",
    "    if signed:\n",
    "        filename += \".signed\"\n",
    "    filename += \".pkl\"\n",
    "    with open(os.path.join(\"results\", filename), \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "# Full experiment run\n",
    "def train_experiment(exp_id, config, trial_num):\n",
    "    print(\"========================================\")\n",
    "    print(f\"Starting Experiment: {exp_id} Trial {trial_num}\")\n",
    "    print(\"Experiment configuration:\")\n",
    "    for key, value in config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(\"========================================\\n\")\n",
    "    torch.manual_seed(trial_num) # todo\n",
    "    np.random.seed()\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    full_train_set, test_loader = load_datasets(transform)\n",
    "    W_droso = load_base_matrix(config_data, signed, config)\n",
    "    model = initialize_model(config, W_droso)\n",
    "    model.to(device)\n",
    "    results = run_training_loop(model, config, full_train_set, test_loader, trial_num,\n",
    "                                  num_epochs, batch_size, fewshot_batch_size)\n",
    "    save_results(exp_id, config, trial_num, results, signed)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for exp_id, config in experiments.items():\n",
    "        for trial_num in range(1, num_trials + 1):\n",
    "            print(f\"\\n=== Training {exp_id} Trial {trial_num} ===\")\n",
    "            train_experiment(exp_id, config, trial_num)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnn_fly_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
