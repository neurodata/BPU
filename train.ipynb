{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Training Twohidden_MLP\n",
      "==============================\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 938/938 [00:12<00:00, 74.69batch/s, loss=0.2356, acc=83.84%, FLOPs=1054.60G]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Test Acc: 91.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 938/938 [00:12<00:00, 76.51batch/s, loss=0.2103, acc=91.43%, FLOPs=2109.20G]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Test Acc: 92.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 938/938 [00:11<00:00, 78.93batch/s, loss=0.1190, acc=93.02%, FLOPs=3163.80G]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Test Acc: 93.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 938/938 [00:11<00:00, 79.31batch/s, loss=0.1063, acc=93.94%, FLOPs=4218.39G]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Test Acc: 94.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 938/938 [00:12<00:00, 76.31batch/s, loss=0.1694, acc=94.73%, FLOPs=5272.99G]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Test Acc: 94.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 938/938 [00:11<00:00, 78.20batch/s, loss=0.1674, acc=95.33%, FLOPs=6327.59G]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Test Acc: 95.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 938/938 [00:11<00:00, 79.88batch/s, loss=0.1292, acc=95.75%, FLOPs=7382.19G]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Test Acc: 95.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 938/938 [00:11<00:00, 79.94batch/s, loss=0.2426, acc=96.19%, FLOPs=8436.79G]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Test Acc: 96.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 938/938 [00:11<00:00, 79.47batch/s, loss=0.1874, acc=96.54%, FLOPs=9491.39G]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Test Acc: 96.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 938/938 [00:11<00:00, 78.63batch/s, loss=0.1532, acc=96.84%, FLOPs=10545.98G]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Test Acc: 96.55%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from thop import profile\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from net import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "experiments = {\n",
    "    # \"Static_BaseRNN\": {\"type\": \"basernn\", \"trainable\": False, \"pruning\": None, \"optim\": \"adam\"},\n",
    "    # \"Static_BaseRNN_random\": {\"type\": \"basernn\", \"trainable\": False, \"pruning\": None, \"optim\": \"adam\", \"init\": \"random\"},\n",
    "    # \"Static_BaseRNN_RandSparse\": {\"type\": \"basernn\", \"trainable\": False, \"pruning\": None, \"optim\": \"adam\", \"init\": \"randsparse\"},\n",
    "    # \"Static_BaseRNN_RandStructure\":{\"type\": \"basernn\", \"trainable\": False, \"pruning\": None, \"optim\": \"adam\", \"init\": \"randstructure\"},\n",
    "    # \"Learnable_BaseRNN\": {\"type\": \"basernn\", \"trainable\": True, \"pruning\": None, \"optim\": \"adam\"},\n",
    "    # \"CWS_Droso\": {\"type\": \"cwsrnn\", \"train_W\": True, \"train_C\": False, \"pruning\": None, \"optim\": \"adam\"},\n",
    "    # \"CWS_TrainC_pruning\": {\"type\": \"cwsrnn\", \"train_W\": True, \"train_C\": True, \"pruning\": \"drosophila\", \"optim\": \"adam\"},\n",
    "    # \"CWS_FixedC_random\": {\"type\": \"cwsrnn\", \"train_W\": True, \"train_C\": False, \"pruning\": None, \"init\": \"random\", \"optim\": \"adam\"},\n",
    "    # \"Static_CNN_RNN\": {\"type\": \"cnnrnn\", \"trainable\": False, \"pruning\": None, \"optim\": \"adam\"},\n",
    "    # \"Static_BaseRNN_fewshot\": {\"type\": \"basernn\", \"trainable\": False, \"pruning\": None, \"optim\": \"adam\", \"fewshot\": True},\n",
    "    # \"Static_CNN_RNN_fewshot\": {\"type\": \"cnnrnn\", \"trainable\": False, \"pruning\": None, \"optim\": \"adam\", \"fewshot\": True},\n",
    "    # \"Single_MLP\": {\"type\": \"singlemlp\", \"optim\": \"adam\"},\n",
    "    \"Twohidden_MLP\": {\"type\": \"twohiddenmlp\", \"optim\": \"adam\"},\n",
    "    # \"Logistic_Regression\": {\"type\": \"logistic\", \"optim\": \"adam\"},\n",
    "    # Hungarian\n",
    "    # \"Hungarian_DrosoInit_DrosoRef\": {\"type\": \"basernn\", \"trainable\": True, \"pruning\": \"hungarian\", \"optim\": \"adam\", \"init\": \"droso\", \"ref\": \"droso\"},\n",
    "    # \"Hungarian_DrosoInit_RandSparseRef\": {\"type\": \"basernn\", \"trainable\": True, \"pruning\": \"hungarian\", \"optim\": \"adam\", \"init\": \"droso\", \"ref\": \"randsparse\"},\n",
    "    # \"Hungarian_DrosoInit_RandStructureRef\": {\"type\": \"basernn\", \"trainable\": True, \"pruning\": \"hungarian\", \"optim\": \"adam\", \"init\": \"droso\", \"ref\": \"randstructure\"},\n",
    "    # \"Hungarian_RandInit_DrosoRef\": {\"type\": \"basernn\", \"trainable\": True, \"pruning\": \"hungarian\", \"optim\": \"adam\", \"init\": \"random\", \"ref\": \"droso\"},\n",
    "    # \"Hungarian_RandInit_RandSparseRef\": {\"type\": \"basernn\", \"trainable\": True, \"pruning\": \"hungarian\", \"optim\": \"adam\", \"init\": \"random\", \"ref\": \"randsparse\"},\n",
    "    # \"Hungarian_RandInit_RandStructureRef\": {\"type\": \"basernn\", \"trainable\": True, \"pruning\": \"hungarian\", \"optim\": \"adam\", \"init\": \"random\", \"ref\": \"randstructure\"},\n",
    "    # \"Hungarian_RandSparseInit_DrosoRef\": {\"type\": \"basernn\", \"trainable\": True, \"pruning\": \"hungarian\", \"optim\": \"adam\", \"init\": \"randsparse\", \"ref\": \"droso\"},\n",
    "    # \"Hungarian_RandSparseInit_RandSparseRef\": {\"type\": \"basernn\", \"trainable\": True, \"pruning\": \"hungarian\", \"optim\": \"adam\", \"init\": \"randsparse\", \"ref\": \"randsparse\"},\n",
    "    # \"Hungarian_RandSparseInit_RandStructureRef\": {\"type\": \"basernn\", \"trainable\": True, \"pruning\": \"hungarian\", \"optim\": \"adam\", \"init\": \"randsparse\", \"ref\": \"randstructure\"}\n",
    "}\n",
    "\n",
    "def get_input_shape(model_type):\n",
    "    return (1, 1, 28, 28) if model_type in [\"cnnrnn\", \"singlemlp\", \"twohiddenmlp\", \"logistic\"] else (1, 28, 28)\n",
    "\n",
    "def prepare_input(data, model):\n",
    "    return data if isinstance(model, CNNRNN) else data.squeeze(1)\n",
    "\n",
    "def train_epoch(model, optimizer, criterion, train_loader, flops_per_sample, cumulative_flops):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    flops_acc_pairs = []\n",
    "  \n",
    "    with tqdm(train_loader, unit=\"batch\", desc=\"Training\") as pbar:\n",
    "        for batch_idx, (data, target) in enumerate(pbar):\n",
    "            data = prepare_input(data.to(device), model)\n",
    "            target = target.to(device)\n",
    "          \n",
    "            batch_flops = flops_per_sample * data.size(0) * 3\n",
    "            cumulative_flops += batch_flops\n",
    "          \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "          \n",
    "            total_loss += loss.item() * data.size(0)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            total += data.size(0)\n",
    "          \n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                flops_acc_pairs.append((cumulative_flops, correct/total))\n",
    "          \n",
    "            pbar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'acc': f\"{correct/total:.2%}\",\n",
    "                'FLOPs': f\"{cumulative_flops/1e9:.2f}G\"\n",
    "            })\n",
    "    \n",
    "    # dynamicaaly pruning: run after each epoch ends\n",
    "    if isinstance(model, BaseRNN) and model.pruning_method == \"hungarian\":\n",
    "        model.apply_hungarian_pruning()\n",
    "    elif isinstance(model, CWSRNN):\n",
    "        model.apply_drosophila_pruning()\n",
    "  \n",
    "    return total_loss/total, correct/total, flops_acc_pairs, cumulative_flops\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    activations_list = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = prepare_input(data.to(device), model)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            if isinstance(model, (BaseRNN, CWSRNN)):\n",
    "                batch_size = data.size(0)\n",
    "                r_t = torch.zeros(batch_size, model.hidden_size, device=device)\n",
    "                act_list = []\n",
    "                \n",
    "                E_t = model.input_to_hidden(data.view(batch_size, -1))\n",
    "                W_eff = model.W if isinstance(model, BaseRNN) else (model.C * model.W * model.s.unsqueeze(1))\n",
    "                r_t = torch.relu(r_t @ W_eff + E_t + r_t)\n",
    "                act_list.append(r_t)\n",
    "                \n",
    "                zero_input = torch.zeros(batch_size, model.input_size, device=device)\n",
    "                for _ in range(9):\n",
    "                    E_t = model.input_to_hidden(zero_input)\n",
    "                    r_t = torch.relu(r_t @ W_eff + E_t + r_t)\n",
    "                    act_list.append(r_t)\n",
    "                \n",
    "                batch_activations = torch.stack(act_list, dim=0)\n",
    "                batch_mean_activations = batch_activations.mean(dim=1)\n",
    "                activations_list.append(batch_mean_activations)\n",
    "                \n",
    "                output = model.hidden_to_output(r_t)\n",
    "            else:\n",
    "                output = model(data)\n",
    "            \n",
    "            correct += output.argmax(dim=1).eq(target).sum().item()\n",
    "            total += target.size(0)\n",
    "    \n",
    "    if activations_list:\n",
    "        activations = torch.stack(activations_list, dim=0).mean(dim=0).cpu().numpy()\n",
    "    else:\n",
    "        activations = None\n",
    "    \n",
    "    return correct / total, activations\n",
    "\n",
    "def train_experiment(exp_id, config):\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    train_set = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "    test_set = datasets.MNIST('./data', train=False, transform=transform)\n",
    "    \n",
    "    if config.get(\"fewshot\", False):\n",
    "        num_classes = 10\n",
    "        samples_per_class = int(len(train_set) * 0.05 / num_classes)\n",
    "        indices = []\n",
    "        targets = np.array(train_set.targets)\n",
    "        \n",
    "        for cls in range(num_classes):\n",
    "            cls_indices = np.where(targets == cls)[0]\n",
    "            sampled_indices = np.random.choice(cls_indices, samples_per_class, replace=False)\n",
    "            indices.extend(sampled_indices)\n",
    "        \n",
    "        train_set = torch.utils.data.Subset(train_set, indices)\n",
    "        print(f\"Few-shot training set size: {len(train_set)} samples\")\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False)\n",
    "  \n",
    "    non_zero = None\n",
    "    W_droso = load_drosophila_matrix('./data/ad_connectivity_matrix.csv')\n",
    "    if config.get('pruning') == 'drosophila':\n",
    "        W_droso, non_zero = load_drosophila_matrix('./data/ad_connectivity_matrix.csv', apply_pruning=True)\n",
    "    elif config.get('pruning') == 'hungarian':\n",
    "        W_droso = load_drosophila_matrix('./data/ad_connectivity_matrix.csv')\n",
    "  \n",
    "    W_init = None\n",
    "    if config.get('init') == 'random':\n",
    "        W_init = torch.randn(W_droso.shape[0], W_droso.shape[0])\n",
    "    elif config.get('init') == 'droso':\n",
    "        W_init = W_droso\n",
    "    elif config.get('init') == 'randsparse':\n",
    "        non_zero_count = np.count_nonzero(W_droso)\n",
    "        total_elements = W_droso.size\n",
    "        mask = torch.zeros(W_droso.shape, dtype=torch.float32)\n",
    "        indices = torch.randperm(total_elements)[:non_zero_count]\n",
    "        mask.view(-1)[indices] = 1\n",
    "        W_init = torch.randn(W_droso.shape) * mask\n",
    "    elif config.get('init') == 'randstructure':\n",
    "        mask = (torch.tensor(W_droso) != 0).float()\n",
    "        W_init = torch.randn(W_droso.shape) * mask\n",
    "    else:\n",
    "        W_init = W_droso if not config.get('trainable', True) else None\n",
    "  \n",
    "    W_ref = None\n",
    "    if config.get('ref') == 'droso':\n",
    "        W_ref = W_droso\n",
    "    elif config.get('ref') == 'randsparse':\n",
    "        non_zero_count = np.count_nonzero(W_droso)\n",
    "        total_elements = W_droso.size\n",
    "        mask = torch.zeros(W_droso.shape, dtype=torch.float32)\n",
    "        indices = torch.randperm(total_elements)[:non_zero_count]\n",
    "        mask.view(-1)[indices] = 1\n",
    "        W_ref = torch.randn(W_droso.shape) * mask\n",
    "    elif config.get('ref') == 'randstructure':\n",
    "        mask = (torch.tensor(W_droso) != 0).float()\n",
    "        W_ref = torch.randn(W_droso.shape) * mask\n",
    "  \n",
    "    if config['type'] == 'basernn':\n",
    "        model = BaseRNN(\n",
    "            784, W_droso.shape[0], 10,\n",
    "            W_init=W_init,\n",
    "            W_ref=W_ref,\n",
    "            trainable=config['trainable'],\n",
    "            pruning_method=config.get('pruning')\n",
    "        )\n",
    "    elif config['type'] == 'cwsrnn':\n",
    "        model = CWSRNN(\n",
    "            784, W_droso.shape[0], 10, W_droso,\n",
    "            train_W=config['train_W'],\n",
    "            train_C=config.get('train_C', False),\n",
    "            non_zero_count=non_zero if config.get('pruning') == 'drosophila' else None\n",
    "        )\n",
    "    elif config['type'] == 'cnnrnn':\n",
    "        model = CNNRNN(torch.tensor(W_droso))\n",
    "    elif config['type'] == 'singlemlp':\n",
    "        model = SingleMLP(784, W_droso.shape[0], 10)\n",
    "    elif config['type'] == 'twohiddenmlp':\n",
    "        model = TwohiddenMLP(784, 1360, 10)\n",
    "    elif config['type'] == 'logistic':\n",
    "        model = LogisticRegression(784, 10)\n",
    "    model.to(device)\n",
    "  \n",
    "    if config['optim'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "    else:\n",
    "        optimizer = FISTAOptimizer(model.parameters(), lr=1e-3, lambda_l1=1e-5)\n",
    "  \n",
    "    input_shape = get_input_shape(config['type'])\n",
    "    dummy_input = torch.randn(input_shape).to(device)\n",
    "    macs, _ = profile(model, inputs=(dummy_input,))\n",
    "    flops_forward = macs * 2\n",
    "\n",
    "    results = {\n",
    "        \"epoch_train_loss\": [], \"epoch_train_acc\": [],\n",
    "        \"epoch_test_acc\": [], \"flops_acc\": [],\n",
    "        \"total_flops\": 0, \"activations\": None\n",
    "    }\n",
    "    cumulative_flops = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "  \n",
    "    for epoch in range(10):\n",
    "        epoch_loss, epoch_acc, flops_pairs, cumulative_flops = train_epoch(\n",
    "            model, optimizer, criterion, train_loader, flops_forward, cumulative_flops\n",
    "        )\n",
    "        test_acc, activations = evaluate(model, test_loader)\n",
    "      \n",
    "        results[\"epoch_train_loss\"].append(epoch_loss)\n",
    "        results[\"epoch_train_acc\"].append(epoch_acc)\n",
    "        results[\"epoch_test_acc\"].append(test_acc)\n",
    "        results[\"flops_acc\"].extend(flops_pairs)\n",
    "        results[\"activations\"] = activations\n",
    "        print(f\"Epoch {epoch+1} | Test Acc: {test_acc:.2%}\")\n",
    "  \n",
    "    results[\"total_flops\"] = cumulative_flops\n",
    "    with open(f\"{exp_id}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for exp_id, config in experiments.items():\n",
    "        print(f\"\\n{'='*30}\\nTraining {exp_id}\\n{'='*30}\")\n",
    "        train_experiment(exp_id, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnn_fly_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
