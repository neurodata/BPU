{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: train.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from thop import profile\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from net import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "experiments = {\n",
    "    \"FixedInit_NoPruning\": {\"type\": \"basernn\", \"trainable\": False, \"pruning\": None, \"optim\": \"adam\"},\n",
    "    \"Learnable_RandomInit\": {\"type\": \"basernn\", \"trainable\": True,  \"pruning\": None, \"optim\": \"adam\"},\n",
    "    # \"CWS_NoPruning\": {\"type\": \"cwsrnn\",  \"train_W\": True, \"pruning\": None, \"optim\": \"adam\"},\n",
    "    # \"CWS_TrainC_Pruning\": {\"type\": \"cwsrnn\", \"train_W\": True, \"train_C\": True, \"pruning\": \"drosophila\", \"optim\": \"adam\"},\n",
    "    # \"CWS_FixedC_Pruning\": {\"type\": \"cwsrnn\", \"train_W\": True, \"train_C\": False, \"pruning\": \"drosophila\", \"optim\": \"adam\"},\n",
    "    # \"L1_FISTA\": {\"type\": \"basernn\", \"trainable\": True,  \"pruning\": None, \"optim\": \"fista\"},\n",
    "    # \"FixedInit_L1\": {\"type\": \"basernn\", \"trainable\": False, \"pruning\": None, \"optim\": \"fista\"},\n",
    "    # \"Learnable_Hungarian\": {\"type\": \"basernn\", \"trainable\": True,  \"pruning\": \"hungarian\", \"optim\": \"adam\"},\n",
    "    # \"CNN_RNN\": {\"type\": \"cnnrnn\",  \"trainable\": False, \"pruning\": None, \"optim\": \"adam\"}\n",
    "}\n",
    "\n",
    "def get_input_shape(model_type):\n",
    "    return (1, 1, 28, 28) if model_type == \"cnnrnn\" else (1, 28, 28)\n",
    "\n",
    "def prepare_input(data, model):\n",
    "    return data if isinstance(model, CNNRNN) else data.squeeze(1)\n",
    "\n",
    "def train_epoch(model, optimizer, criterion, train_loader, flops_per_sample, cumulative_flops):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    flops_acc_pairs = []\n",
    "  \n",
    "    with tqdm(train_loader, unit=\"batch\", desc=\"Training\") as pbar:\n",
    "        for batch_idx, (data, target) in enumerate(pbar):\n",
    "            data = prepare_input(data.to(device), model)\n",
    "            target = target.to(device)\n",
    "          \n",
    "            batch_flops = flops_per_sample * data.size(0) * 3  \n",
    "            cumulative_flops += batch_flops\n",
    "          \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "          \n",
    "            total_loss += loss.item() * data.size(0)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            total += data.size(0)\n",
    "          \n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                flops_acc_pairs.append((cumulative_flops, correct/total))\n",
    "          \n",
    "            pbar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'acc': f\"{correct/total:.2%}\",\n",
    "                'FLOPs': f\"{cumulative_flops/1e9:.2f}G\"\n",
    "            })\n",
    "  \n",
    "    return total_loss/total, correct/total, flops_acc_pairs, cumulative_flops\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = prepare_input(data.to(device), model)\n",
    "            output = model(data)\n",
    "            correct += output.argmax(dim=1).eq(target.to(device)).sum().item()\n",
    "            total += target.size(0)\n",
    "    return correct / total\n",
    "\n",
    "def train_experiment(exp_id, config):\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    train_set = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "    test_set = datasets.MNIST('./data', train=False, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False)\n",
    "  \n",
    "    non_zero = None\n",
    "    if config.get('pruning') == 'drosophila':\n",
    "        W_droso, non_zero = load_drosophila_matrix('./data/ad_connectivity_matrix.csv', apply_pruning=True)\n",
    "    elif config.get('pruning') == 'hungarian':\n",
    "        W_droso = load_drosophila_matrix('./data/ad_connectivity_matrix.csv')\n",
    "    else:\n",
    "        W_droso = load_drosophila_matrix('./data/ad_connectivity_matrix.csv')\n",
    "  \n",
    "    if config['type'] == 'basernn':\n",
    "        model = BaseRNN(\n",
    "            28, W_droso.shape[0], 10,\n",
    "            W_init=W_droso if not config['trainable'] else None,\n",
    "            trainable=config['trainable'],\n",
    "            pruning_method=config.get('pruning')\n",
    "        )\n",
    "    elif config['type'] == 'cwsrnn':\n",
    "         model = CWSRNN(\n",
    "            28, W_droso.shape[0], 10, W_droso,\n",
    "            train_W=config['train_W'],\n",
    "            train_C=config.get('train_C', False),\n",
    "            non_zero_count=non_zero if config.get('pruning') == 'drosophila' else None\n",
    "        )\n",
    "    elif config['type'] == 'cnnrnn':\n",
    "        model = CNNRNN(torch.tensor(W_droso))\n",
    "    model.to(device)\n",
    "  \n",
    "    if config['optim'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    else:\n",
    "        optimizer = FISTAOptimizer(model.parameters(), lr=1e-3, lambda_l1=1e-5)\n",
    "  \n",
    "    input_shape = get_input_shape(config['type'])\n",
    "    dummy_input = torch.randn(input_shape).to(device)\n",
    "    macs, _ = profile(model, inputs=(dummy_input,))\n",
    "    flops_forward = macs * 2\n",
    "  \n",
    "    results = {\n",
    "        \"epoch_train_loss\": [], \"epoch_train_acc\": [],\n",
    "        \"epoch_test_acc\": [], \"flops_acc\": [],\n",
    "        \"total_flops\": 0\n",
    "    }\n",
    "    cumulative_flops = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "  \n",
    "    for epoch in range(5):\n",
    "        epoch_loss, epoch_acc, flops_pairs, cumulative_flops = train_epoch(\n",
    "            model, optimizer, criterion, train_loader, flops_forward, cumulative_flops\n",
    "        )\n",
    "        test_acc = evaluate(model, test_loader)\n",
    "      \n",
    "        results[\"epoch_train_loss\"].append(epoch_loss)\n",
    "        results[\"epoch_train_acc\"].append(epoch_acc)\n",
    "        results[\"epoch_test_acc\"].append(test_acc)\n",
    "        results[\"flops_acc\"].extend(flops_pairs)\n",
    "        print(f\"Epoch {epoch+1} | Test Acc: {test_acc:.2%}\")\n",
    "  \n",
    "    results[\"total_flops\"] = cumulative_flops\n",
    "    with open(f\"{exp_id}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for exp_id, config in experiments.items():\n",
    "        print(f\"\\n{'='*30}\\nTraining {exp_id}\\n{'='*30}\")\n",
    "        train_experiment(exp_id, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
